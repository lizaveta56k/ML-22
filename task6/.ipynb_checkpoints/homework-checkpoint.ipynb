{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel, RFECV, SequentialFeatureSelector\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.datasets import make_classification, load_wine, load_breast_cancer, load_diabetes, load_digits\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(x, y, auto_scaled=True, title=None, clusters=None):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.scatter(x, y, c=clusters, cmap='bwr')\n",
    "    \n",
    "    if not auto_scaled:\n",
    "        plt.axis('square')\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def return_X_y(data, target_column):\n",
    "    return data.drop(target_column, axis=1), data[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_sklearn = load_wine(as_frame=True)\n",
    "wine_data, wine_labels = wine_sklearn['data'], wine_sklearn['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise  1 - Scaling (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform standardization for wine dataset (`wine_data`) using only basic python, numpy and pandas (without using `StandardScaler` and sklearn at all). Implementation of function (or class) that can get dataset as input and return standardized dataset as output is preferrable, but not necessary.\n",
    "\n",
    "Compare you results (output) with `StandardScaler`.\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "- 1 point for functional version, 2 points for implementing scaling as sklearn pipeline compartible class. \n",
    "- Maximum for the exercise is 2 points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple version (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 point\n",
    "def scale(X):\n",
    "    return (X - X.mean()) / np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(np.array(scale(wine_data)), StandardScaler().fit_transform(wine_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Version (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_13964/2725336298.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Lizka\\AppData\\Local\\Temp/ipykernel_13964/2725336298.py\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    def fit(self, X, y=None):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# 2 points\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, copy=True, with_mean=True, with_std=True):\n",
    "        # your code here\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # your code here\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(CustomScaler().fit_transform(wine_data), StandardScaler().fit_transform(wine_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise  2 - Visualization (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted earlier, standardization/normalization of data can be crucial for some distance-based ML methods.\n",
    "\n",
    "Let’s generate some toy example of unnormalized data and visualize the importance of this process once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_0 = np.random.randn(1000) * 10   \n",
    "feature_1 = np.concatenate([np.random.randn(500), np.random.randn(500) + 5])\n",
    "data = np.column_stack([feature_0, feature_1])\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(data[:, 0], data[:, 1], auto_scaled=True, title='Data (different axes units!)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** on the plot above axes are scaled differently and we can clearly see two potential *classes/clusters*. In fact `matplotlib` performed `autoscaling` (which is basically can be considered as `MinMaxScaling` of original data) just for better visualization purposes.\n",
    "\n",
    "Let's turn this feature off and visualize the original data on the plot with equally scaled axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(data[:, 0], data[:, 1], auto_scaled=False , title='Data (equal axes units!)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This picture is clearly less interpretable, but much closer to \"how distance-based algorithm see the original data\": separability of data is hardly noticable only because the variation (std) of x-feature is much bigger in absolute numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform `StandardScaling` and `MinMaxScaling` of original data; visualize results for each case (**use `plot_scatter` with `auto_scaled=False`**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaling (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code\n",
    "data_scaled = MinMaxScaler().fit_transform(data)\n",
    "plot_scatter(data_scaled[:, 0], data_scaled[:, 1], auto_scaled=False , title='MinMaxScaler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code\n",
    "data_scaled = StandardScaler().fit_transform(data)\n",
    "plot_scatter(data_scaled[:, 0], data_scaled[:, 1], auto_scaled=False , title='StandardScaler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Bonus) K-means (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrate the impact of scaling on basic distance-based clustering algorithm [K-means](https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1) using `data` generated above.\n",
    "\n",
    "**NOTE:** basically, you don't need understanding K-means algorithm here, you just need to:\n",
    "\n",
    "1) run algorithm (with k=2, k - number of clusters/classes) on unscaled data    \n",
    "2) run algorithm (with k=2) on scaled data    \n",
    "3) plot results: highlight different clusters using different colors.\n",
    "\n",
    "You can use this [question](https://stats.stackexchange.com/questions/89809/is-it-important-to-scale-data-before-clustering/89813) as a hint, but I recommend you to plot results using `plot_scatter` with `equal_scaled=True`: it might help you to intuitively understand the reasons of such scaling impact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code\n",
    "Kmean = KMeans(n_clusters=2)\n",
    "Kmean.fit(data)\n",
    "\n",
    "Kmean_scaled = KMeans(n_clusters=2)\n",
    "Kmean_scaled.fit(data_scaled)\n",
    "\n",
    "plt.scatter(data[:, 0], data[:, 1], s =50, c='#FB8F78')\n",
    "plt.scatter(Kmean.cluster_centers_[0][0], Kmean.cluster_centers_[0][1], s=120, c='#FB4721', marker='s')\n",
    "plt.scatter(Kmean.cluster_centers_[1][0], Kmean.cluster_centers_[1][1], s=120, c='#F9A90D', marker='s')\n",
    "\n",
    "plt.scatter(data_scaled[:, 0], data_scaled[:, 1], s =50, c='#73AAFD')\n",
    "plt.scatter(Kmean_scaled.cluster_centers_[0][0], Kmean_scaled.cluster_centers_[0][1], s=120, c='#2D5FFF', marker='s')\n",
    "plt.scatter(Kmean_scaled.cluster_centers_[1][0], Kmean_scaled.cluster_centers_[1][1], s=120, c='#7AC9FE', marker='s')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_scaled[:, 0], data_scaled[:, 1], s =50, c='#73AAFD')\n",
    "plt.scatter(Kmean_scaled.cluster_centers_[0][0], Kmean_scaled.cluster_centers_[0][1], s=120, c='#2D5FFF', marker='s')\n",
    "plt.scatter(Kmean_scaled.cluster_centers_[1][0], Kmean_scaled.cluster_centers_[1][1], s=120, c='#7AC9FE', marker='s')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдения:\n",
    "Выше набор данных, который имеет два четких кластера, но некластеризованное измерение намного больше, чем кластеризованное измерение. Кластеризация ненормализованных данных не удалась. Кластеризация нормализованных данных работает очень хорошо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise  3 - Preprocessing Pipeline (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_train, wine_val, wine_labels_train, wine_labels_val = train_test_split(wine_data, wine_labels, \n",
    "                                                                            test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model (for example, `LogisticRegression(solver='liblinear', penalty='l1')` on raw `wine_train` data; then train same model after data scaling; then add feature selection (and train model again on scaled data). For each experiment all required preprocessing steps (if any) should be wrapped into sklearn pipeline.\n",
    "\n",
    "Measure `accuracy` of all 3 approaches on `wine_val` dataset. Describe and explain results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(useStandartScaler=False, useMinMaxScaler=False, solver='liblinear', penalty= 'l1'):    \n",
    "    if useStandartScaler : \n",
    "        return Pipeline([\n",
    "            ('sca', StandardScaler()),\n",
    "            ('reg', LogisticRegression(solver=solver, penalty=penalty))\n",
    "        ])\n",
    "    elif useMinMaxScaler : \n",
    "        return Pipeline([\n",
    "            ('sca', MinMaxScaler()),\n",
    "            ('reg', LogisticRegression(solver=solver, penalty=penalty))\n",
    "        ])\n",
    "    else:\n",
    "        return Pipeline([\n",
    "            ('reg', LogisticRegression(solver=solver, penalty=penalty))\n",
    "        ])\n",
    "\n",
    "display(make_model(True))\n",
    "display(make_model(False, True))\n",
    "display(make_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_evaluate(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    disp = metrics.plot_confusion_matrix(clf, X_test, y_test, normalize='true')\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc_train = metrics.accuracy_score(y_train, y_pred_train)\n",
    "    acc_test = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print('Accuracy train = ' + str(acc_train))\n",
    "    print('Accuracy test = ' + str(acc_test))\n",
    "    \n",
    "    return acc_train, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_raw = make_model()\n",
    "train_acc, test_acc = fit_evaluate(logistic_raw, wine_train, wine_labels_train, wine_val, wine_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_raw2 = make_model(True)\n",
    "train_acc, test_acc = fit_evaluate(logistic_raw2, wine_train, wine_labels_train, wine_val, wine_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_raw2 = make_model(False, True)\n",
    "train_acc, test_acc = fit_evaluate(logistic_raw2, wine_train, wine_labels_train, wine_val, wine_labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод тут написать надо!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - manual PCA (5 points)\n",
    "The task is to solve PCA as an optimization problem, without explicitly doing eigen value decomposition.\n",
    "In the most general setting PCA is minimization of reconstruction error of a projection of given rank $q$\n",
    "\n",
    "$$\\min_{\\mu, \\lambda_1,\\ldots, \\lambda_n, \\mathbf{V}_q} \\sum_{i=1}^n ||x_i - \\mu - \\mathbf{V}_q \\lambda_i||^2$$\n",
    "\n",
    "With a number of steps that can be found here https://stats.stackexchange.com/a/10260 this task transforms to\n",
    " $$\\max_{u_i} \\sum_{i=1}^q u_i^T \\mathbf{S} u_i$$\n",
    " where $\\mathbf{S}$ is the sample covariance matrix (after standartization) and $u_1, \\ldots, u_q$ are the $q$ are orthonormal columns in $\\mathbf{V}_q$.\n",
    " Let us solve this optimization problem with `scipy.optimize` library.\n",
    " \n",
    " Additional 2 point are given for visualization of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data, wine_labels = wine_sklearn['data'], wine_sklearn['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a covariance matrix of standartized data and assing it to S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code\n",
    "sc = StandardScaler()   \n",
    "wine_data_scaled = sc.fit_transform(wine_data) \n",
    "\n",
    "mean_data = np.mean(wine_data_scaled,axis=0)\n",
    "S = (wine_data_scaled-mean_data).T @ (wine_data_scaled-mean_data)/(wine_data_scaled.shape[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, the following assert should be Ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(np.linalg.norm(S), 5.787241159764733)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def objective(x):\n",
    "    # your code: write objective of the problem (don't forget that scipy does min while we need max)\n",
    "\n",
    "def norm_constraint(x):\n",
    "    # your code: constaraint norm of x to be 1, function should return 0 if constraint holds\n",
    "\n",
    "con1 = {'type': 'eq', 'fun': norm_constraint}\n",
    "\n",
    "x0 = # your code: initial vector to start optimization\n",
    "\n",
    "sol = minimize(objective, \n",
    "               x0, \n",
    "               constraints = [con1]\n",
    "              )\n",
    "x0 = sol.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray! We have first vector! Let's do another one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthogonality_constraint(x):\n",
    "    # your code: x should be orthogonal to x0, function should return 0 if constraint holds\n",
    "\n",
    "con2 = {'type': 'eq', 'fun': orthogonality_constraint}\n",
    "\n",
    "x1 = # your code: initial vector to start optimization\n",
    "\n",
    "\n",
    "sol = minimize(objective, \n",
    "               x1, \n",
    "               constraints = #your code\n",
    "              )\n",
    "\n",
    "x1 = sol.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your solution is correct, the following asserts should be Ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(x0@S@x0, 4.732436977583595)\n",
    "assert np.allclose(x1@S@x1, 2.5110809296451233)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the points after applying custom dimension reduction with 2 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize = (8,8))\n",
    "# ax = fig.add_subplot(1,1,1) \n",
    "# ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "# ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "# ax.set_title('2 component PCA', fontsize = 20)\n",
    "# targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "# colors = ['r', 'g', 'b']\n",
    "# for target, color in zip(targets,colors):\n",
    "#     indicesToKeep = finalDf['target'] == target\n",
    "#     ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "#                , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "#                , c = color\n",
    "#                , s = 50)\n",
    "# ax.legend(targets)\n",
    "# ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 - Boruta (3 points)\n",
    "\n",
    "Let us classify handwritten digits 0, 1 and 2. \n",
    "To make task not so easy the images are binarized (no shadows of gray present) as it happens with xerocopied documents.\n",
    "\n",
    "Let us also find out to which parts of an image there's no need to look in order to clasify three digits of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(n_class=3, return_X_y=True, as_frame=True)\n",
    "X = (X>10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1,3,figsize=(10,4))\n",
    "for i in range(3):\n",
    "    ax[i].imshow(X.iloc[i].values.reshape(8,8))\n",
    "    ax[i].set_title(f\"This is digit {y[i]}.\")\n",
    "plt.suptitle(\"First three images.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test, let test size be 30% of the dataset and fix random state to 42:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_val.shape[0] == 162\n",
    "assert y_val.sum() == 169"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a RandomForestClassifier with max_depth=13 and evaluate it's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9876543209876543\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=13)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_val)\n",
    "\n",
    "acc = metrics.accuracy_score(y_val, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc > 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use Boruta to find redundand pixels. If the package is not installed in your system, uncomment and run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(max_depth=13, n_estimators=62,\n",
       "                                          random_state=RandomState(MT19937) at 0x28983F06040),\n",
       "         n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x28983F06040)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "\n",
    "feat_selector = BorutaPy(RandomForestClassifier(max_depth=13), \n",
    "                         n_estimators='auto', \n",
    "                         verbose=0, \n",
    "                         max_iter=100,\n",
    "                         random_state=42)\n",
    "\n",
    "feat_selector.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us print redundant pixels as a mask. Does the result looks similar to mine (or to Among us chracters)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False  True  True  True  True False False]\n",
      " [False False  True False False  True False False]\n",
      " [False False  True  True  True  True False False]\n",
      " [False False  True  True  True  True False False]\n",
      " [False False  True  True  True  True False False]\n",
      " [False False  True  True  True  True False False]\n",
      " [False False  True  True  True  True  True False]\n",
      " [False False  True  True False  True  True False]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = np.array(feat_selector.support_).reshape(8,8)\n",
    "plt.imshow(mask);\n",
    "\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end let us redo  classification but only with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9938271604938271\n"
     ]
    }
   ],
   "source": [
    "clf_filtered = RandomForestClassifier(max_depth=13)\n",
    "X_filtered = feat_selector.transform(X_train.values)\n",
    "X_val_filtered = feat_selector.transform(X_val.values)\n",
    "\n",
    "clf_filtered.fit(X_filtered, y_train)\n",
    "y_pred=clf_filtered.predict(X_val_filtered)\n",
    "\n",
    "acc = metrics.accuracy_score(y_val, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc > 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materials & References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. General article about feature engineering and selection (main reference):\n",
    "https://github.com/Yorko/mlcourse.ai/blob/master/jupyter_english/topic06_features_regression/topic6_feature_engineering_feature_selection.ipynb\n",
    "\n",
    "2. Feature engineering/preprocessing, using scikit-learn API (great code examples, but really brief explanation):    \n",
    "https://scikit-learn.org/stable/modules/preprocessing\n",
    "\n",
    "3. Feature scaling/normalization:     \n",
    "https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35\n",
    "\n",
    "4. Log Transform/power transform:    \n",
    "https://medium.com/@kyawsawhtoon/log-transformation-purpose-and-interpretation-9444b4b049c9\n",
    "\n",
    "6. Missing values preprocessing using scikit-learn API (great code examples, great explanation):    \n",
    "https://scikit-learn.org/stable/modules/impute.html\n",
    "\n",
    "7. Feature selection scikit-learn API (great code examples, great explanation):   \n",
    "https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n",
    "8. Melbourne housing dataset source:    \n",
    "https://www.kaggle.com/anthonypino/melbourne-housing-market"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
